# COMMENT TOXICITY
An NLP language model which is able to classify different range of comments 

![C9A31747-FBED-41A5-8820ED507C404BB0_source](https://github.com/abin-k/comment_toxicity/assets/116078614/ca06e219-045c-48fe-8383-3899d1d47487)

# RELEVANCE
Comment toxicity refers to the negative, harmful, or hostile language used in online comments. It can range from cyberbullying and hate speech to personal 
attacks and harassment. Comment toxicity has become a growing concern in recent years, as it can have significant negative impacts on individuals, communities, 
and society. It can harm mental health, disrupt civil discourse, damage reputations, and result in legal issues. It is essential to address this issue to promote
a healthy and productive online environment that fosters respect, civility, and inclusivity.

# PROJECT
Developed a NLP language model which is able to classify different range of comments and detect toxic comments among them. The model use TextVectorization methode
to classify text.The model is deployed using gradio, which is an open-source Python library that enables developers to quickly and easily create customizable
UI components for their machine learning models (basically used to create web-based user interfaces for the models)
![Screenshot (24)](https://github.com/abin-k/comment_toxicity/assets/116078614/8c6eb453-0dd0-424f-86ab-293310245045)
